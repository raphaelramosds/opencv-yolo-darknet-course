{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf362a6",
   "metadata": {},
   "source": [
    "# Detectando objetos com YOLO v4 e OpenCV\n",
    "\n",
    "## Visão geral\n",
    "\n",
    "No notebook anterior, utilizamos o framework Darknet para realizar a detecção de objetos em imagens com o You only look once (YOLO). Entretanto, também é possível empregar o módulo cv2, que corresponde à implementação do OpenCV em Python, para executar a mesma tarefa, sem a necessidade de compilar (buildar) o framework Darknet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79510f2c",
   "metadata": {},
   "source": [
    "## Etapa 1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e74d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32825917",
   "metadata": {},
   "source": [
    "## Etapa 2 - Conectando com o Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desnecessario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3369e9d",
   "metadata": {},
   "source": [
    "## Etapa 3 - Carregando os arquivos do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55039d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Obter pesos, configuracao da arquitetura e labels da rede neural do modelo\n",
    "yolov3 = utils.carregar_yolov3()\n",
    "yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a rede YOLOv3 no módulo DNN (Deep Neural Network) do OpenCV\n",
    "net = cv2.dnn.readNet(yolov3.config_path, yolov3.weights_path)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbfc95",
   "metadata": {},
   "source": [
    "## Etapa 4 - Definindo mais configurações para a detecção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97650246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Gerar cores RGB aleatorias para \"colorir\" o contorno da caixa delimitadora de cada label/classe detectada\n",
    "# NOTE: o OpenCV trabalha com o sistema de cores BGR ao inves do RGB\n",
    "colors = np.random.randint(0, 255, size=(len(yolov3.labels), 3), dtype='uint8')\n",
    "colors[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017dd73",
   "metadata": {},
   "source": [
    "Como é possível ver a seguir, uma rede neural pode ter mais de uma camada de saída, ou seja, camadas que recebem conexões da camada anterior, mas não se conectam a nenhuma camada seguinte.\n",
    "\n",
    "**ATENÇÃO:** o número de camadas de saída em uma CNN não deve ser confundido com o número de labels (classes) que o modelo é capaz de prever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b4ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os identificadores (IDs) de todas as camadas da rede\n",
    "ln = net.getLayerNames()\n",
    "\n",
    "# Retorna os índices (baseados em 1) das camadas de saida\n",
    "ln_saida_indices = net.getUnconnectedOutLayers()\n",
    "\n",
    "# IDs das camadas de saída\n",
    "ln_saida_ids = tuple(ln[i - 1] for i in ln_saida_indices)\n",
    "\n",
    "print('Todas as camadas:', ln)\n",
    "print('Camadas de saída:', ln_saida_ids)\n",
    "print('Total de camadas: ' + str(len(ln)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f09d3",
   "metadata": {},
   "source": [
    "## Etapa 5 - Carregando a imagem onde será feita a detecção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = utils.carregar_imagem_cv2('dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_cp = imagem.copy()\n",
    "(H, W) = imagem_cp.shape[:2]\n",
    "print(f'Dimensoes da imagem: {H} x {W} px')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67dd4b",
   "metadata": {},
   "source": [
    "## Etapa 6 - Processando a imagem de entrada\n",
    "\n",
    "Antes que a Rede Neural Convolucional (CNN) possa realizar inferências, a imagem precisa passar por um pré-processamento.\n",
    "O objetivo aqui é preparar os dados de forma que a rede consiga trabalhar corretamente, e logo após realizar as deteções (ver imagem da Etapa 8). \n",
    "\n",
    "Um dos métodos usados para isso é o blobFromImage, que aplica duas transformações principais:\n",
    "\n",
    "1. **Subtração da média (mean subtraction):** remove valores médios de cor da imagem, reduzindo problemas relacionados à variação de iluminação. Isso garante que a CNN foque mais nos padrões visuais (formas, bordas, texturas) e menos nas diferenças de brilho.\n",
    "\n",
    "2. **Redimensionamento (resizing):** ajusta a largura e altura da imagem para o tamanho de entrada exigido pela CNN.\n",
    "\n",
    "Dessa forma, todas as imagens entram na rede com o mesmo formato, independentemente da resolução original.\n",
    "\n",
    "> O termo *blob* é utilizado no contexto de redes neurais convolucionais para definir uma imagem que foi redimensionada e manipulada para ser utilizadas como entrada da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "fator_escala = 1 / 255.0            # Fator em que a imagem sera redimensionada\n",
    "tamanho_esperado_rn = (416, 416)    # Tamanho da imagem esperado pela CNN\n",
    "trocar_rgb = True                   # Inverter canais RGB (o OpenCV trabalha com BGR)?\n",
    "cortar_imagem = False               # Cortar imagem para se adequar ao tamanho esperado?\n",
    "\n",
    "inicio = time.time()\n",
    "\n",
    "# Converter imagem para formato de blob\n",
    "blob = cv2.dnn.blobFromImage(\n",
    "    image=imagem,\n",
    "    scalefactor=fator_escala,\n",
    "    size=tamanho_esperado_rn,\n",
    "    swapRB=trocar_rgb,\n",
    "    crop=cortar_imagem,\n",
    ")\n",
    "\n",
    "# Enviar imagem para a rede neural\n",
    "net.setInput(blob=blob)\n",
    "\n",
    "# Processar a imagem na CNN e obter as respostas das camadas de saída\n",
    "# O método forward percorre a rede: processa a imagem desde as camadas de entrada até as camadas de saída\n",
    "layer_outputs = net.forward(ln_saida_ids)\n",
    "\n",
    "termino = time.time()\n",
    "\n",
    "print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5538149",
   "metadata": {},
   "source": [
    "## Etapa 7 - Definindo as variáveis para a detecção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold       = 0.5   # Threshold (eh de fato o objeto?): detecções com probabilidade (confiança) de ser o objeto abaixo desse percentual sao descartadas\n",
    "threshold_NMS   = 0.3   # Non-Max supression (tem um objeto?): caixas com probabilidade (confiança) de ter um objeto abaixo desse percentual sao descartadas\n",
    "caixas          = []\n",
    "confiancas      = []        \n",
    "IDclasses       = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ffee1",
   "metadata": {},
   "source": [
    "## Etapa 8 - Realizando a predição\n",
    "\n",
    "A detecção retornada por uma camada de saída da rede YOLO é codificada em uma matriz cujas linhas correspondem as caixas delimitadoras e as colunas a coeficientes de probabilidade, como mostrado na imagem a seguir\n",
    "\n",
    "![Image size function](./img/cnn-yolo.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada camada de saída da rede neural (a rede pode ter várias saídas)\n",
    "for output in layer_outputs:\n",
    "    # Para cada detecção feita nessa camada\n",
    "    for detection in output:\n",
    "        # Os primeiros 5 valores de detection são: [pc, bx, by, bw, bh]\n",
    "        # A partir da posição 5 temos as probabilidades de cada classe\n",
    "        scores = detection[5:]\n",
    "        \n",
    "        # Recupera o índice da classe com maior probabilidade\n",
    "        classeID = np.argmax(scores)\n",
    "        \n",
    "        # Recupera o valor da confiança (probabilidade de realmente ser esse objeto)\n",
    "        confianca = scores[classeID]\n",
    "\n",
    "        # Só continua se a confiança for maior que o limiar definido\n",
    "        if confianca > threshold:\n",
    "            # print(\"scores: \" + str(scores))\n",
    "            # print(\"classe mais provavel: \" + str(classeID))\n",
    "\n",
    "            # Construção da caixa delimitadora ao redor do objeto detectado\n",
    "            # detection[0:4] = [centerX, centerY, width, height], normalizados entre 0 e 1\n",
    "            # Multiplicamos por [W, H, W, H] para escalar para o tamanho real da imagem\n",
    "            caixa = detection[0:4] * np.array([W, H, W, H])\n",
    "            (centerX, centerY, width, height) = caixa.astype(\"int\")\n",
    "\n",
    "            # Conversão de coordenadas: de centro (centerX, centerY) para canto superior esquerdo (x, y)\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "\n",
    "            # Adiciona a caixa calculada à lista de caixas\n",
    "            caixas.append([x, y, int(width), int(height)])\n",
    "\n",
    "            # Adiciona a confiança dessa detecção à lista de confiabilidades\n",
    "            confiancas.append(float(confianca))\n",
    "\n",
    "            # Adiciona o ID da classe detectada à lista de classes\n",
    "            IDclasses.append(classeID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confiancas), len(confiancas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IDclasses), len(IDclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91409cfc",
   "metadata": {},
   "source": [
    "## Etapa 9 - Aplicando a Non-maxima Suppresion (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "objetos = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)\n",
    "objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar probabilidade dos objetos detectados\n",
    "{int(obj): confiancas[obj]*100 for obj in objetos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3643888",
   "metadata": {},
   "source": [
    "## Etapa 10 - Mostrando o resultado da deteção na imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f040c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(objetos) > 0:\n",
    "    for i in objetos.flatten():\n",
    "        (x, y) = (caixas[i][0], caixas[i][1])\n",
    "        (w, h) = (caixas[i][2], caixas[i][3])\n",
    "\n",
    "        objeto = imagem_cp[y: y+h, x:x+w]\n",
    "\n",
    "        cor = [int(c) for c in colors[IDclasses[i]]]\n",
    "\n",
    "        cv2.rectangle(imagem, (x,y), (x+w, y+h), cor, 2)\n",
    "        texto = \"{}: {:.4f}\".format(yolov3.labels[IDclasses[i]], confiancas[i])\n",
    "        cv2.putText(imagem, texto, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor, 2)\n",
    "\n",
    "cv2.imwrite('resultado.jpg', imagem)\n",
    "\n",
    "utils.mostrar_imagem_cv2(imagem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-yolo-darknet-qw1bPAyb-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
